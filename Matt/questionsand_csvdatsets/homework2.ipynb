{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Homework 2\n",
    "\n",
    "## Guidelines\n",
    "- Answer in the Markdown or code cells given below the questions.\n",
    "- Comment code where appropriate for clarity."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Problem 1\n",
    "In the following exercise, we will perform Bayesian inference to estimate a parameter $\\lambda$ using data generated from an exponential distribution with the unknown parameter $\\lambda$, i.e. $Y \\sim Exponential(\\lambda) $ with the exponential density function given by:\n",
    "\n",
    "$$p(y_{i}|\\lambda) = \\lambda e^{-\\lambda y_{i}}$$\n",
    "\n",
    "where $\\lambda> 0$.  We load the data below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y = [1.11659426, 0.14591992, 0.9003231 , 1.05267893, 0.59665315,\n",
    "       0.62196716, 0.0501256 , 2.2569046 , 0.59176357, 0.27908501,\n",
    "       0.09001983, 0.05302138, 0.19794783, 0.71657887, 0.94523602,\n",
    "       0.44210873, 0.17189032, 0.4104458 , 0.30163634, 1.0564698 ,\n",
    "       0.15813088, 1.57609817, 0.62982101, 0.37747863, 0.10139393,\n",
    "       2.44308245, 0.52684559, 0.73786292, 0.21034834, 0.44559072,\n",
    "       0.16346868, 0.51826629, 0.0785872 , 0.21773059, 0.14507205,\n",
    "       0.26167145, 1.30119327, 0.00881093, 0.77196405, 0.96493311,\n",
    "       0.57850034, 0.6733615 , 0.53110575, 2.84934561, 0.09835044,\n",
    "       0.11307157, 1.3428276 , 0.1704228 , 0.41692473, 1.48197104,\n",
    "       0.05143844, 0.2103084 , 0.33847738, 1.19901459, 0.13828761,\n",
    "       0.56981701, 0.07084937, 0.63245193, 0.66973814, 0.23941691,\n",
    "       0.1019617 , 0.77316563, 0.19573404, 0.54167001, 0.18553303,\n",
    "       0.42725298, 0.59527454, 0.91323428, 0.7351151 , 0.65058701,\n",
    "       0.0504051 , 0.45197308, 0.04504415, 0.28518144, 1.34887045,\n",
    "       0.69967626, 0.23990762, 0.03207982, 0.00399789, 0.03258423,\n",
    "       1.05381261, 0.08938671, 1.04649714, 0.1472991 , 0.02720062,\n",
    "       0.01421303, 0.23445255, 0.95165048, 0.20992524, 0.19655135,\n",
    "       0.64897642, 0.27907629, 1.21557848, 0.27363763, 0.29139022,\n",
    "       0.40552119, 0.09628245, 0.09214942, 0.19160858, 0.41977512]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.1\n",
    "Assume a $\\text{Gamma}(2,2)$ prior for the parameter $\\lambda$. In a single plot, overlay the prior density of $\\lambda$ and posterior density of $\\lambda$ given the samples $Y$. Plot the densities over the interval $(0,6]$.\n",
    "\n",
    "Hint: You may read more about the gamma distribution in [the SciPy documentation](https://docs.scipy.org/doc/scipy/reference/generated/scipy.stats.gamma.html)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy.stats as stats\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# support\n",
    "support = np.linspace(0.01, 6, 100)\n",
    "\n",
    "# likelihood\n",
    "# add your code here\n",
    "likelihood = \n",
    "\n",
    "# prior\n",
    "# add your code here\n",
    "prior = \n",
    "\n",
    "# posterior\n",
    "# add your code here\n",
    "\n",
    "post = \n",
    "\n",
    "# plot\n",
    "fig, ax = plt.subplots(1,1)\n",
    "ax.plot(support, prior)\n",
    "ax.plot(support, post)\n",
    "ax.legend(labels=[\"prior\", \"posterior | data\"]);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.2 \n",
    "Plot the density of $Gamma(2+length(Y),2+\\sum_{y_i \\in Y} y_i)$ and the posterior density of $\\lambda$ we got in 1.1 over the interval $(0,6]$ separately. What can you conclude? Do the prior distribution and the posterior distribution belong to the same probability distribution family? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot the given gamma distribution on the support\n",
    "# add your code here\n",
    "\n",
    "gvalue = \n",
    "\n",
    "ax1 = plt.subplot(2,1,1)\n",
    "ax1.plot(support,gvalue, scale=1/(2+sum(Y))));\n",
    "ax1.legend(labels=[\"Gamma\"])\n",
    "ax2 = plt.subplot(2,1,2)\n",
    "ax2.plot(support, post,'r');\n",
    "ax2.legend(labels=[\"posterior | data\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Answer:\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.3\n",
    "In Bayesian statistics, if the posterior distribution $p(\\theta | x)$ is in the same probability distribution family as the prior probability distribution $p(\\theta)$, then the prior is called a conjugate prior for $p(\\theta | x)$. So if given a conjugate prior, the posterior would be easy to identify. But in many cases, we do not have a conjugate prior. Usually, we would use Monte Carlo simulation methods.\n",
    "\n",
    "Implement a Metropolis-Hastings algorithm to sample from the posterior distribution of $\\lambda$ using the data $Y$. Use a normal distribution $\\mathcal{N}(\\lambda^{(i-1)},1/2)$ as the proposal distribution. Print the acceptance rate and estimate the probability that $\\lambda$ is smaller than 2 using the samples.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Metropolis-Hastings\n",
    "np.random.seed(seed=553)\n",
    "\n",
    "lbd_0 = 1  # initial value\n",
    "m = 10000  # number of proposal samples\n",
    "lbd = [lbd_0]   # list to store accepted samples\n",
    "\n",
    "\n",
    "# add your code here\n",
    "\n",
    "\n",
    "\n",
    "# compute the acceptance rate\n",
    "acpt_rate = \n",
    "\n",
    "print('The acceptance rate of MH is {0:0.4f}'. format(acpt_rate))\n",
    "\n",
    "# compute the estimated probability using the samples in \"lbd\"\n",
    "estprob_MH = \n",
    "\n",
    "print('The estimated probability by MH is {0:0.4f}'. format(estprob_MH))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.4\n",
    "Also, complete the code below for rejection sampling and compare the results of the MH sampling and the rejection sampling with the true value. Which sampling method is better based on the acceptance ratios and the probability estimations?\n",
    "\n",
    "Hint: You can use $Gamma(2+length(Y),2+\\sum_{y_i \\in Y} y_i)$ to compute the true probability $P(\\lambda<2)$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Rejection sampling\n",
    "\n",
    "np.random.seed(seed=436)\n",
    "\n",
    "M = 10**(-15)   # target density less than M times proposal density\n",
    "\n",
    "S = stats.norm.rvs(size=10000, loc = 0, scale=2)   # proposal samples\n",
    "\n",
    "# target function\n",
    "def f(x):\n",
    "    \n",
    "    # add your code here\n",
    "\n",
    "    values = \n",
    "    \n",
    "    return values\n",
    "\n",
    "#proposal function\n",
    "g = stats.norm.pdf(S,loc = 1,scale=1)\n",
    "\n",
    "#ratio\n",
    "ratio = f(S)/g\n",
    "\n",
    "#sampling\n",
    "samples = S[stats.uniform.rvs(size=10000) <= ratio/M]\n",
    "\n",
    "# compute the acceptancerate\n",
    "acpt_rate =     # add your code here\n",
    "\n",
    "print('The acceptance rate of rejection sampling is {0:0.4f}'. format(acpt_rate))\n",
    "\n",
    "\n",
    "# estimating the probability\n",
    "estprob_r =     # add your code here\n",
    "\n",
    "\n",
    "print('The estimated probability by rejection sampling is {0:0.4f}'. format(estprob_r))\n",
    "\n",
    "# compute the true probability\n",
    "# add your code here\n",
    "\n",
    "prob_t = \n",
    "print('The true probability is {0:0.4f}'. format(prob_t))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Answer:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Problem 2\n",
    "We load and preprocess the [breast cancer](https://scikit-learn.org/stable/datasets/toy_dataset.html#breast-cancer-dataset) dataset from sklearn.datasets. \n",
    "\n",
    "Read the description of the dataset. Note that the target is encoded as 0 for class \"malignant\" and \"1\" for class \"benign\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.datasets import load_breast_cancer\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "cancer_bunch = load_breast_cancer()\n",
    "cancer_pred = pd.DataFrame(cancer_bunch['data'], columns=cancer_bunch['feature_names'])\n",
    "cancer_targ = pd.DataFrame(cancer_bunch['target'], columns=[\"Class\"])\n",
    "\n",
    "\n",
    "scaler = StandardScaler()\n",
    "cancer_pred = scaler.fit_transform(cancer_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.1\n",
    "We will proceed to perform KNN classification. Split the dataset into separate training and test sets using a test size of 1/5 and random_state=636."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test =  # add your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.2\n",
    "For K between 1 and 30 inclusive, create a plot of the mean accuracies of KNN from 4-fold cross validation on the **training set**. Which K you would pick based on the results?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "# build K-NN classificaiton models for k between 1 and 30.\n",
    "k = (range(1,31))\n",
    "knn_score = [] # list to store the average cross-validation accuracies\n",
    "for i in k:\n",
    "\n",
    "    # add your code here\n",
    "    \n",
    "\n",
    "# Plot\n",
    "plt.plot(k, knn_score, \"-o\", label = \"accuracy\")\n",
    "plt.xlabel('number of neighbors')\n",
    "# Set the y axis label of the current axis.\n",
    "plt.ylabel('accuracy')\n",
    "# Set a title of the current axes.\n",
    "plt.title('Accuracy for KNN with different neighbors')\n",
    "# show a legend on the plot\n",
    "plt.legend()\n",
    "# Display a figure.\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Answer:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.4\n",
    "For the K that you identified, print the accuracy and visualize the confusion matrix of the predictions on the test set of the KNN model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import seaborn as sns \n",
    "\n",
    "\n",
    "#fit KNN to the training set with the K you pick and predict results on the test set\n",
    "\n",
    "# add your code here\n",
    "\n",
    "\n",
    "\n",
    "#Report the accuracy scores on test set.\n",
    "acc =      # add your code here\n",
    "\n",
    "print('accuracy score on test set: {0:0.4f}'. format(acc))\n",
    "\n",
    "#confusion matrix\n",
    "cm_knn =    # add your code here\n",
    "\n",
    "plt.figure(figsize=(6,6))\n",
    "\n",
    "confusion_m = pd.DataFrame(data=cm_knn, columns=['Actual Positive:1', 'Actual Negative:0'], \n",
    "                                 index=['Predict Positive:1', 'Predict Negative:0'])\n",
    "sns.heatmap(confusion_m , annot=True, fmt='d', cmap='YlGnBu')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Problem 3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below we load NB.csv, which contains 2500 univariate observations, each of which are generated by one of two beta distributions. Recall that the density function for a $\\text{Beta}(a, b)$ distribution is\n",
    "\n",
    "$$f(x|a,b) = \\begin{cases}\\frac{\\Gamma(a+b)}{\\Gamma(a)\\Gamma(b)} x^{a-1}(1-x)^{b-1} & 0 \\leq x \\leq 1 \\\\\n",
    "0 & \\text{otherwise}\n",
    "\\end{cases}$$\n",
    "\n",
    "where $a,b>0$ and $\\Gamma(\\cdot)$ is the Gamma function. We are going to build a classification model to distinguish which of the two beta distribution each data point is coming from."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the data from NB.csv\n",
    "NB = pd.read_csv(\"NB.csv\")\n",
    "display(NB)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.1\n",
    "We know that each observation in our dataset is generated from one of two beta distributions, but we do not know the parameters of these distributions. To estimate these parameters, we will employ the following method-of-moments estimators:\n",
    "\n",
    "\\begin{align*}\n",
    "\\hat a = \\bar x\\left(\\frac{\\bar x(1-\\bar x)}{s^2_x} - 1\\right) \\\\\\\\\n",
    "\\hat b = (1-\\bar x)\\left(\\frac{\\bar x(1-\\bar x)}{s^2_x} - 1\\right)\n",
    "\\end{align*}\n",
    "\n",
    "where $\\bar x$ is sample mean, $s^2_x$ is **unbiased** sample variance.\n",
    "  \n",
    "Program a function `MOM_estimators(x)` that returns method-of-moments estimates of $a$ and $b$ given data `x` generated from a beta distribution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def MOM_estimators(x):\n",
    "\n",
    "    # add your code here\n",
    "    \n",
    "    a =  # estimator for parameter a \n",
    "    b =  # estimator for parameter b\n",
    "    return(a, b)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.2\n",
    "Complete the code below for a Beta Naive Bayes classification by using MOM estimators. Apply the sample-weighted prior for the two beta distributions. Use [scipy.stats.beta](https://docs.scipy.org/doc/scipy/reference/generated/scipy.stats.beta.html) for the beta distribution.\n",
    " \n",
    "Hint: You can modify the codes for Gaussian Naive Bayes classification in lecture notes, but substitute the Gaussian density function by the Beta density function using MOM estimators for $a$ and $b$ in the formula."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy.stats as stats\n",
    "# create a beta naive bayes function based on Method-of-Moments estimatior class\n",
    "class beta_naive_bayes(object):\n",
    "    # define estimate function to get needed parameters for gamma distribution\n",
    "    def estimate(self, X, C):\n",
    "        self.param = dict()# create param and will save parameters in it\n",
    "        # calculate required parameters for different classes from training set\n",
    "        for k in np.unique(C): # 0,1\n",
    "            \n",
    "            # add your code here\n",
    "\n",
    "            self.param[k] = (prior, a, b) # set class k's parameters into self.param[k]\n",
    "        return self\n",
    "    \n",
    "    # define prediction function to get predict result from test set T\n",
    "    def prediction(self, T):\n",
    "        k_pred = -1 * np.ones(T.size) # create an empty k_pred in advance for reserving prediction values\n",
    "        # evaluate posterior for each point and find maximum\n",
    "        for i in range(T.size): \n",
    "\n",
    "            # add your code here\n",
    "            \n",
    "        return k_pred"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.4\n",
    "We proceed to perform classification on our data. Split the dataset into a training and test set using 4/5 as the test size and a random state of 436. Print the test set accuracy (correct predictions / total predictions)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_test_split\n",
    "X, X_test, C, y_test =      # add your code here\n",
    "\n",
    "k_pred1 =  beta_naive_bayes().estimate(X, C).prediction(X_test)\n",
    "\n",
    "# compute the accuracy\n",
    "acc =      # add your code here\n",
    "\n",
    "print('The accuracy on test set is {0:0.4f}'. format(acc))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Problem 4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We load the \"Smarket.csv\" dataset, which contains observations on the [S&P 500 stock market index](https://en.wikipedia.org/wiki/S%26P_500) from the beginning of 2001 until the end of 2005. The features in the dataset are as follows:\n",
    "\n",
    "- Lag1 through Lag5: Percentage returns relative to each of the five previous trading days.\n",
    "- Volume: Number of shares traded on the previous day in billions.\n",
    "- Today: Percentage return on the trading day.\n",
    "- Direction: Whether the market was up (2) or down (1) on the trading day."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "smarket = pd.read_csv(\"Smarket.csv\") ## Substitute appropriate filepath if necessary.\n",
    "display(smarket)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this problem, we want to train classifers that use the index performance of the two previous day to predict the market direction on a trading day."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.1 \n",
    "Plot the sample features \"Lag1\" vs. \"Lag2\" in a scatterplot. Color the points by the market direction on the trading day."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.colors import ListedColormap\n",
    "######################################\n",
    "### Write your code starting from here\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.2\n",
    "Create two objects of type `numpy.ndarray` called `X_train` and `y_train` based on the DataFrame `smarket` that \n",
    "represent a training set based on the performance of the two last days before the trading day, using only the data from years 2001 through 2004.\n",
    "\n",
    "Furthermore, create two objects of type `numpy.ndarray` called `X_test` and `y_test` that represent a test set that includes all the trading days in the year 2005. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.3\n",
    "Fit classifiers that use linear discriminant analysis (LDA) and quadratic discriminant analysis (QDA) to predict the S&P 500 stock market index direction on the trading days of the year 2005 from the data of the years 2001 through 2004, using only the features selected in 4.2.\n",
    "\n",
    "Print both the training and test accuracy for each model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.4\n",
    "For each model, plot a \"classification_map\" the visualizes the decision boundaries.\n",
    "\n",
    "Hint: You may use parts of the code for the classification_map function of lectures 11â€“12."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def classification_map(X,y,classifier,X_test=None,y_test=None,h=0.01,figsize=(10,10)):\n",
    "    import matplotlib.pyplot as plt\n",
    "    from matplotlib.colors import ListedColormap\n",
    "    ######################################\n",
    "    ### Write your code starting from here\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
